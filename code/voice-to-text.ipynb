{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introduction\n",
                "\n",
                "Transcribe audio into whatever language the audio is in.\n",
                "\n",
                "# Setup"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "import openai\n",
                "from pathlib import Path\n",
                "import difflib\n",
                "\n",
                "from dotenv import load_dotenv, find_dotenv\n",
                "_ = load_dotenv(find_dotenv())\n",
                "openai.api_key = os.getenv('OPENAI_API_KEY')"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Simple example\n",
                "\n",
                "## Create mp3 data {.smaller}\n",
                "\n",
                "- Use [ttsmp3](https://ttsmp3.com/) to generate your audio data\n",
                "- save it as `example.mp3` in your Downloads folder\n",
                "\n",
                "- Example text to use in [ttsmp3](https://ttsmp3.com/) :\n",
                "\n",
                "```{markdown}\n",
                "Welcome to the world of automatic speech recognition with OpenAI's Whisper API. Whisper is an automatic speech recognition system trained on a massive amount of multilingual and multitask supervised data collected from the web. It is designed to convert spoken language into written text, making transcription tasks a breeze.\n",
                "\n",
                "```\n",
                "\n",
                "\n",
                "## SSML {.smaller}\n",
                "\n",
                "- You may use [Speech Synthesis Markup Language (SSML)](https://docs.aws.amazon.com/polly/latest/dg/supportedtags.html) to customize the output\n",
                "\n",
                "- Add a **break**: Mary had a little lamb <break time=\"1s\"/> Whose fleece was white as snow.\n",
                "- **Emphasizing** words: I already told you I <emphasis level=\"strong\">really like </emphasis> that person.\n",
                "- **Speed**: For dramatic purposes, you might wish to <prosody rate=\"slow\">slow down the speaking rate of your text.</prosody>\n",
                "Or if you are in a hurry <prosody rate=\"fast\">your may want to speed it up a bit.</prosody>\n",
                "- **Pitch**: Do you like sythesized speech <prosody pitch=\"high\">with a pitch that is higher than normal?</prosody> Or do you prefer your speech <prosody pitch=\"-20%\">with a somewhat lower pitch?</prosody>\n",
                "- **Whisper** <amazon:effect name=\"whispered\">If you make any noise, </amazon:effect> she said, <amazon:effect name=\"whispered\">they will hear us.</amazon:effect>\n",
                "- **Conversations**: It is possible to switch between speakers within the text. Just use the following format:\n",
                "  - [speaker:Brian] Hello Emma\n",
                "  - [speaker:Emma] Hey Brian\n",
                "  - [speaker:Brian] How are you doing?\n",
                "  - [speaker:Emma] I am fine. May i invite you to a cup of tea?\n",
                "\n",
                "\n",
                "## Load data"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "path_to_example = Path.home() / 'Downloads/example.mp3' "
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "audio_file= open(path_to_example, \"rb\")"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- 'r': Read mode. File is opened for reading. \n",
                "- 'b': Binary mode. File is opened in binary mode, which is used for non-text files (e.g., image and sound files).\n",
                "\n",
                "## Transcribe\n",
                "\n",
                "File uploads are currently limited to 25 MB and the following input file types are supported: mp3, mp4, mpeg, mpga, m4a, wav, and webm."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
                "transcript"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n",
                "```{bash}\n",
                "<OpenAIObject at 0x117dea450> JSON: {\n",
                "  \"text\": \"Welcome to the world of Automatic Speech Recognition with OpenAI's Whisper API. Whisper is an automatic speech recognition system trained on a massive amount of multilingual and multitask supervised data collected from the web. It is designed to convert spoken language into written text, making transcription tasks a breeze.\"\n",
                "}\n",
                "\n",
                "```\n",
                "\n",
                "\n",
                "# Extract only text"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "text_output = transcript['text']\n",
                "text_output"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Output:\n",
                "\n",
                "\n",
                "\n",
                "```{markdown}\n",
                "\"Welcome to the world of Automatic Speech Recognition with OpenAI's Whisper API. Whisper is an automatic speech recognition system trained on a massive amount of multilingual and multitask supervised data collected from the web. It is designed to convert spoken language into written text, making transcription tasks a breeze.\"\n",
                "\n",
                "```\n",
                "\n",
                "# Save text"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "write_to_output = Path.home() / 'Downloads/output.txt' "
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "with open(write_to_output, 'w') as file:\n",
                "    file.write(text_output)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Workflow for multiple files\n",
                "\n",
                "- We will use an example with multiple .mp3 files which are stored in the 'Downloads' folder\n",
                "\n",
                "- Note that the files will be renamed during the process\n",
                "\n",
                "## Prepare environment\n",
                "\n",
                "- Create a new folder called `data` in your Downloads folder\n",
                "- Place at least two mp3 files in your `data` folder\n",
                "\n",
                "## Obtain file names"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "downloads_folder = Path.home() / 'Downloads/data'\n",
                "\n",
                "mp3_files = [f for f in downloads_folder.iterdir() if f.suffix == '.mp3']"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Obtain time of storage "
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Get file paths along with their stored time\n",
                "file_details = [(f, f.stat().st_mtime) for f in mp3_files]"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sort files according to time\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "sorted_files = sorted(file_details, key=lambda x: x[1])"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Move and rename files\n",
                "\n",
                "- Move the files to a folder of your choice (we use our data folder) and rename the files to 01_audio, 02_audio, etc.\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "destination_folder = Path.home() / 'Downloads/data'\n",
                "\n",
                "for idx, (file_path, _) in enumerate(sorted_files):\n",
                "    dest_path = destination_folder / f\"{str(idx+1).zfill(2)}_audio.mp3\"\n",
                "    file_path.rename(dest_path)\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Transcripe helper function\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "def transcribe_audio(audio_file_path):\n",
                "    \"\"\"\n",
                "    Transcribe the given audio file using OpenAI's Whisper ASR system.\n",
                "    \"\"\"\n",
                "    audio_file_path = Path(audio_file_path)  # Convert to Path object if it's not already\n",
                "    with audio_file_path.open(\"rb\") as audio_file:\n",
                "        response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
                "    return response[\"text\"]"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Apply function"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "data_folder = destination_folder\n",
                "\n",
                "# Get a list of all audio files in the /data/ folder\n",
                "audio_files = sorted(data_folder.glob('*.mp3'))\n",
                "\n",
                "for audio_file in audio_files:\n",
                "    # Transcribe the audio file\n",
                "    transcription = transcribe_audio(audio_file)\n",
                "\n",
                "    # Create a new txt file name based on the audio file's name\n",
                "    txt_file_name = audio_file.stem + \".txt\"\n",
                "    txt_file_path = data_folder / txt_file_name\n",
                "\n",
                "    # Save the transcription to the txt file\n",
                "    with txt_file_path.open('w') as txt_file:\n",
                "        txt_file.write(transcription)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save as markdown\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "markdown_content = []\n",
                "\n",
                "# Iterate through all txt files in the /data/ folder\n",
                "txt_files = sorted(data_folder.glob('*.txt'))\n",
                "\n",
                "for txt_file in txt_files:\n",
                "    # Read the content of the txt file\n",
                "    with txt_file.open('r') as file:\n",
                "        file_content = file.read()\n",
                "    \n",
                "    # Append the file name as a headline and then the content to the markdown content list\n",
                "    markdown_content.append(f\"# {txt_file.name}\\n\\n{file_content}\\n\")\n",
                "\n",
                "# Join all the markdown content pieces to create the final document\n",
                "final_markdown = \"\\n\".join(markdown_content)\n",
                "\n",
                "# Save the combined content to a markdown file\n",
                "output_file = data_folder / \"combined_audio_transcriptions.md\"\n",
                "with output_file.open('w') as file:\n",
                "    file.write(final_markdown)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Post processing with GPT\n",
                "\n",
                "## System prompt"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "system_prompt = \"You are a helpful assistant. Your task is to correct any spelling discrepancies in the transcribed text. Only add necessary punctuation such as periods, commas, and capitalization, and use only the context provided\""
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Helper function"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "def generate_corrected_transcript(temperature, system_prompt, transcribed_text):\n",
                "    response = openai.ChatCompletion.create(\n",
                "        model=\"gpt-3.5-turbo\",\n",
                "        temperature=temperature,\n",
                "        messages=[\n",
                "            {\n",
                "                \"role\": \"system\",\n",
                "                \"content\": system_prompt\n",
                "            },\n",
                "            {\n",
                "                \"role\": \"user\",\n",
                "                \"content\": transcribed_text\n",
                "            }\n",
                "        ]\n",
                "    )\n",
                "    return response['choices'][0]['message']['content']"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Correct data for multiple files\n",
                "\n",
                "- In the appendix is an example of how to correct a single file"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Directory containing the transcription files\n",
                "data_folder = destination_folder\n",
                "\n",
                "# List to hold the corrected transcriptions\n",
                "corrected_transcriptions = []\n",
                "\n",
                "# Iterate through each individual .txt file\n",
                "for txt_file_path in sorted(data_folder.glob('??_audio.txt')):\n",
                "    # Read the transcription from the file\n",
                "    with txt_file_path.open('r') as txt_file:\n",
                "        transcription = txt_file.read()\n",
                "\n",
                "    # Post-process the transcription using GPT-4\n",
                "    corrected_text = generate_corrected_transcript(0.5, system_prompt, transcription)\n",
                "    \n",
                "    # Append the file name as a headline and then the corrected content to the list\n",
                "    corrected_transcriptions.append(f\"# {txt_file_path.name}\\n\\n{corrected_text}\\n\")\n",
                "\n",
                "# Combine the corrected transcriptions and save them to the new markdown file\n",
                "output_file = data_folder / \"corrected_text.md\"\n",
                "with output_file.open('w') as out_file:\n",
                "    out_file.write(\"\\n\".join(corrected_transcriptions))"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Show differences"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Define file paths\n",
                "original_file_path = Path.home() / 'Downloads/data/combined_audio_transcriptions.md' \n",
                "\n",
                "corrected_file_path = Path.home() / 'Downloads/data/corrected_text.md'\n",
                "\n",
                "# Read the content of both markdown files\n",
                "with original_file_path.open('r') as f:\n",
                "    original_content = f.readlines()\n",
                "\n",
                "with corrected_file_path.open('r') as f:\n",
                "    corrected_content = f.readlines()\n",
                "\n",
                "# Generate a side-by-side comparison in HTML format\n",
                "differ = difflib.HtmlDiff()\n",
                "comparison_html = differ.make_file(original_content, corrected_content)\n",
                "\n",
                "# Add custom CSS for content wrapping and better visualization\n",
                "custom_css = \"\"\"\n",
                "<style>\n",
                "    body {\n",
                "        font-family: Arial, sans-serif;\n",
                "        margin: 20px;\n",
                "    }\n",
                "    table.diff {\n",
                "        width: 100%;\n",
                "        border-collapse: collapse;\n",
                "    }\n",
                "    td {\n",
                "        vertical-align: top;\n",
                "        padding: 5px;\n",
                "        border: 1px solid #ddd;\n",
                "        white-space: pre-wrap;\n",
                "        word-break: break-word;\n",
                "        overflow-wrap: break-word;\n",
                "    }\n",
                "</style>\n",
                "\"\"\"\n",
                "\n",
                "# The rest of your code remains the same...\n",
                "\n",
                "\n",
                "# Insert the custom CSS into the generated HTML content\n",
                "comparison_html = comparison_html.replace('<head>', '<head>' + custom_css)\n",
                "\n",
                "\n",
                "# Save the HTML comparison to a file\n",
                "output_html_path = Path.home() / 'Downloads/data/comparison.html'\n",
                "with output_html_path.open('w') as f:\n",
                "    f.write(comparison_html)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Read the transcriptions from the markdown file\n",
                "markdown_path = Path('YOUR/PATH/DATA.md')\n",
                "with markdown_path.open('r') as md_file:\n",
                "    transcriptions = md_file.read()\n",
                "\n",
                "# Post-process the transcriptions using GPT-4\n",
                "corrected_text = generate_corrected_transcript(0.2, system_prompt, transcriptions)\n",
                "\n",
                "# save the corrected text to a new markdown file\n",
                "output_path = Path('YOUR/PATH/corrected_data.md')\n",
                "with output_path.open('w') as out_file:\n",
                "    out_file.write(corrected_text)"
            ],
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "language": "python",
            "display_name": "Python 3 (ipykernel)"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}